---
title: "Affective Multimodal Agents with Proactive Knowledge Grounding for Emotionally Aligned Marketing Dialogue"
authors:
- Lin Yu
- Xiaofei Han
- Yifei Kang
- Chiung-Yi Tseng
- Danyang Zhang
- Ziqian Bi
- Zhimo Han

venues:
  - "(Under review) Journal: Digital Signal Processing"
  - "arXiv preprint"

acceptance: ""

date: 2025-11-18

type: "preprint"

selected: false

project: "https://ctseng777.github.io/AffectMind/"

cover: "/assets/images/covers/AffectMind_algorithms.drawio.png"

abstract: >-
  Recent advances in large language models (LLMs) have enabled fluent dialogue systems, but most remain reactive and struggle in emotionally rich, goal-oriented settings such as marketing conversations. To address this limitation, we propose AffectMind, a multimodal affective dialogue agent that performs proactive reasoning and dynamic knowledge grounding to sustain emotionally aligned and persuasive interactions. AffectMind combines three components: a Proactive Knowledge Grounding Network (PKGN) that continuously updates factual and affective context from text, vision, and prosody; an Emotionâ€“Intent Alignment Model (EIAM) that jointly models user emotion and purchase intent to adapt persuasion strategies; and a Reinforced Discourse Loop (RDL) that optimizes emotional coherence and engagement via reinforcement signals from user responses. Experiments on two newly curated marketing dialogue datasets, MM-ConvMarket and AffectPromo, show that AffectMind outperforms strong LLM-based baselines in emotional consistency (+26%), persuasive success rate (+19%), and long-term user engagement (+23%), highlighting emotion-grounded proactivity as a key capability for commercial multimodal agents.


links:
  Code: "https://ctseng777.github.io/AffectMind/"
  Paper: ""
---
