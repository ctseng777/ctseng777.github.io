---
title: "Is GPT-OSS Good? A Comprehensive Evaluation of OpenAI's Latest Open Source Models"
authors:
- Ziqian Bi
- Keyu Chen
- Chiung-Yi Tseng
- Danyang Zhang
- Tianyang Wang
- Hongying Luo
- Lu Chen
- Junming Huang
- Jibin Guan
- Junfeng Hao
- Junhao Song
venue: "arXiv preprint"
date: 2025-08-17
arxiv: "2508.12461"
type: "preprint"
selected: true
project: "https://ai-agent-lab.github.io/gpt-oss/"
cover: "/assets/images/covers/gpt-oss.png"
abstract: >-
  This paper evaluates OpenAI's first open weight large language models since GPT-2, comparing two mixture of experts models (120B and 20B parameters) against six contemporary open source models. Our comprehensive evaluation reveals that gpt-oss-20B consistently outperforms gpt-oss-120B on several benchmarks, providing important insights into the performance characteristics of these newly released models.
links:
  Code: "https://ai-agent-lab.github.io/gpt-oss/"
  Paper: "https://arxiv.org/abs/2508.12461"
---
A comprehensive evaluation of OpenAI's latest open source models, analyzing the performance of mixture of experts architectures and providing insights into the effectiveness of different parameter scales in open weight language models.
